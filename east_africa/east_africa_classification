/**** Start of imports. If edited, may not auto-convert in the playground. ****/
var rgb_vis = {"opacity":1,"bands":["b3","b2","b1"],"min":2643.4286587190527,"max":4022.9989507085565,"gamma":1},
    map_centre = /* color: #98ff00 */ee.Geometry.Point([41.74464016557656, -15.761113939339115]),
    region_extent = 
    /* color: #0b4a8b */
    /* shown: false */
    /* displayProperties: [
      {
        "type": "rectangle"
      }
    ] */
    ee.Geometry.Polygon(
        [[[30.58253079057656, -1.110150033997842],
          [30.58253079057656, -30.572237471480907],
          [51.017101103076556, -30.572237471480907],
          [51.017101103076556, -1.110150033997842]]], null, false),
    eg_area = 
    /* color: #ffc82d */
    /* shown: false */
    ee.Geometry.Polygon(
        [[[39.30567800403558, -2.14380791283709],
          [38.07520925403558, -5.213271852184973],
          [37.19630300403558, -7.745607660192833],
          [39.21778737903558, -13.871996848695606],
          [35.87794362903558, -17.50974995109439],
          [33.32911550403558, -20.583215652904375],
          [34.12013112903558, -23.19267735921931],
          [31.219740504035574, -26.30503413040521],
          [30.692396754035574, -29.642036358442212],
          [30.626478785285574, -30.507184922969966],
          [34.10914480091058, -30.497719020942302],
          [36.56726254706963, -26.222017591830895],
          [38.67663754706963, -22.783814045307793],
          [39.20398129706963, -19.588292829735373],
          [41.22546567206963, -19.588292829735373],
          [42.80749692206963, -28.02110945977892],
          [49.22351254706963, -27.78809548132923],
          [50.19030942206963, -20.74330773609798],
          [50.84948910956963, -15.609847956935804],
          [50.41003598456963, -10.603957829763257],
          [48.12487973456963, -9.218731537475657],
          [44.69714535956963, -12.62697547098248],
          [42.89538754706963, -12.240745015499678],
          [41.18152035956963, -7.828048621874418],
          [42.54382504706963, -2.6660071156528553],
          [42.71960629706963, -1.4363504429492293],
          [42.74157895331963, -1.194715110033472],
          [40.06091489081963, -1.194715110033472]]]);
/***** End of imports. If edited, may not auto-convert in the playground. *****/
///////////////////////////////
// Global coral atlas project - East Africa region
// Contact: mitchell.lyons@gmail.com
// Description:
// - Developing a process to combine OBIA and supervised classification
// - This script loads the pixel-based and segmentation data and applies a mchaine learning classifier
// - Corresponding '_datagen' script performs the data gathering/segmentation, '_calval' generates the trianing samples
///////////////////////////////

// Table of contents
// 1. Setting constants
// 2. Data loads & vis
// 3. Divide into potential mapping zones (not utilised yet really)
// 4. Train and fit models
// 5. Export data

// Load and libraries needed
var map_palettes = require('users/mitchest/global_reefs:Modules/colour_pals')
var param_module = require('users/mitchest/global_reefs:Modules/reef_params')
var slider_module = require('users/mitchest/global_reefs:Modules/threshold_sliders')

// ###########################################
// SENSOR GENERICS
var sensor_params = param_module.dove         //<------------ THIS IS WHERE YOU CHOOSE THE SENSOR
// REGION AND SENSOR SPECIFIC LOAD PATHS
var region_params = param_module.east_africa  //<------------ THIS IS WHERE YOU CHOOSE THE REGION
//  ^^ all the data paths are in this module ^^
// ###########################################

// 1. Setting constants

// These will get written to the asset metadata 

var vars = {
  
  // analysis type
  geomorphic: true, // map geomorphic zonation (when set to true) or benthic habitat (when set to false)
  use_benthic_points: false, // true = use benthic field points instead of map
  thresholding: false, // should all the thresholdable layers be added to the map?
  threshold_pixels: true, // whether the thresholding should be on the pixel or segment data
  
  // analysis parameters
  image_data_scale: sensor_params.pixel, // pixel size of the image data
  
  /*
  Choose whether pixels, segments or both should be used to train the classifier. Choose from,
  
  pixel data:
  ['b1_p', 'b2_p', 'b3_p', 'b4_p', 'depth_p', 'depth_stdDev_p', 'red_stdDev_p', 'depth_maxent_p', 'b1_savg_p', 'b2_savg_p', 'rb_p', 'gb_p', 'rg_p']
  
  object data:
  ['b1_s', 'b2_s', 'b3_s', 'b4_s', 'depth_s', 'rb_s', 'gb_s', 'rg_s']
    */
  input_bands: ['b1_p', 'b2_p', 'b3_p', 'b4_p', 'depth_p', 'red_stdDev_p', 'b1_s', 'b2_s', 'b3_s', 'b4_s', 'depth_s', 'rb_s', 'gb_s', 'rg_s'],
  blue_nir_bands: (sensor_params.sname == 'dove') ? ['b1','b4'] : ['B2','B5'], // only handles Landsat/Sentinel-2/Dove
  blue_band: (sensor_params.sname == 'dove') ? 'b1' : 'B2', // only handles Landsat/Sentinel-2/Dove
  class_field: 'class_num', // the field in the training data that stores the class integer
  //small_object_filter: 50, // size in pixels (output scale) for small object removal
  
  /*// add relative band brightness to predictor variables?
  use_brightness: true, <<----- now done in the *_datagen script */
  
  // zone thresholds
  //reef_top_depth: 4.5, // areas above this depth will be split into 'reef top'
  
  // classification params
  rf_trees: 15, // number of random forest trees (per class)
  rf_minLeafPop: 1, // minimum leaf population for random forest
  rf_varPerSplit: 0, // default sqrt(n(k))
  set_seed: 42, // set a seed so results are repeatable

  // class information for classification, sampling and reporting
  local_epsg: region_params.epsg,
  // trim input data
  trim_training_data: false, // if true, will trim the training data set by the % below
  trim_training_perc: 0.80,
  
  // results/layers to show
  show_intermediates: false, // show separate intermediate layers (e.g. reef top, reef crest etc.)
  show_eg_area: true, // contrain the map add to the corresponding example_area polygon geomtery (you can change that)
                              // - you can either set this, or have it false and just navigate to the area you want to see (keeping in mind ALL tiles in the zoom area will calcualte)
  /*
  Use test mode?
  This pars down the training computation
  to test (in real-time in the map viewer)
  whether classification output is working
  */
  test_mode: false,
  
  // export options
  do_export: false, // export the results?
  export_scale: sensor_params.pixel, // pixel size to export at
  geomorph_output_name: region_params.sname + '_' + 'geo',
  benthic_output_name: region_params.sname + '_' + 'benthic',
  asset_output: region_params.asset, // asset path

}

// if running in test mode, over-write the trianing params
if (vars.test_mode) {
  vars.rf_trees = 10
  vars.trim_training_data = true
  vars.trim_training_perc = 0.2
}


// 2. Data loads & vis

// load input data
var pixsegs = ee.ImageCollection(region_params.pixels).mosaic().regexpRename('(^.*$)','$1_p')
                  .addBands(
              ee.ImageCollection(region_params.segments).mosaic().regexpRename('(^.*$)','$1_s')  
                           )
                  .select(vars.input_bands)
var geomorph = ee.FeatureCollection(region_params.geo_train_library)
var benthic = ee.FeatureCollection(region_params.benthic_train_library)
if (vars.use_benthic_points) var benthic_pts = ee.FeatureCollection(region_params.benthic_pts)

// Load training data samples (from '*_calval' script)

//classes_mapped_geo:       [ 2,  11,  12,  13,   14,   15,  16,  21,  22,  23,  24  ], // classes to map
//classes_mapped_names_geo: ['D','SL','DL','IRF','ORF','RR','TRF','SS','SE','PL','OCL'],
//classes_mapped_benthic:       [ 3,    4,    11,   12,   13,   14,   15,   16,  17], // classes to map
//classes_mapped_names_benthic: ['MAN','MU', 'SA', 'RU', 'RO', 'SG', 'CA', 'CO', 'AL'],

var training_data = (vars.geomorphic) ? geomorph : benthic // Set the training points to either geomorphic or benthic
// trim the data (randomly) if needed
if (vars.trim_training_data) {
  training_data = training_data.randomColumn("random")
  training_data = training_data.filter(ee.Filter.lte("random", vars.trim_training_perc))
}

print("Number of training samples:", training_data.size())

Map.centerObject(map_centre, 5)
Map.addLayer(pixsegs, {min: 100, max: 2000}, 'segments + pixels', false)


// ################################################
// Add the threshold slider layers
// ################################################

if (vars.thresholding) {
  
  var thresh_dat = (vars.threshold_pixels) ? pixels : segments
  
  var bw_pal = {'palette': '000000,ffffff','min':-9999, 'max': -9999}
  var red_pal = {'palette': '000000,f03b20','min':-9999, 'max': -9999}
  
  // N.B. these are all generic and come from mitchest/global_reefs/Modules/threshold_sliders
  slider_module.add_depth(thresh_dat)
  slider_module.add_waves(thresh_dat)
  slider_module.add_slope(thresh_dat)
  slider_module.add_b1(thresh_dat)
  slider_module.add_b2(thresh_dat)
  slider_module.add_b3(thresh_dat)
  slider_module.add_b4(thresh_dat)
  if (sensor_params.sname != 'dove') slider_module.add_b5(thresh_dat)
  slider_module.add_depthsd(thresh_dat)
  slider_module.add_redsd(thresh_dat)
  slider_module.add_ndwi(thresh_dat)
  slider_module.add_idm(thresh_dat)
  slider_module.add_depth_depthvar(thresh_dat)
  
}
  
// ################################################
// End of adding threshold slider layers
// ################################################


// 3. Divide into potential mapping zones

/*

var reef_top = pixels.select('depth').gt(vars.reef_top_depth)

if (vars.show_intermediates) {
  Map.addLayer(reef_top, {}, "reef top", false)
}

*/


// 4. Train and fit models

// filter nulls
training_data = training_data.filter(ee.Filter.notNull(vars.input_bands))
print('Number of sampels after null filter', training_data.size())

// parameterise and train the classifier (random forest in this case)
var rf_classifier = ee.Classifier.randomForest({
  numberOfTrees: vars.rf_trees,
  minLeafPopulation: vars.rf_minLeafPop,
  variablesPerSplit: vars.rf_varPerSplit,
  seed: vars.set_seed
}).train(training_data, vars.class_field, vars.input_bands)
// fit the classificaiton model
var raw_classification = pixsegs.classify(rf_classifier).toUint8()

var classesList={
   classes_mapped_geo:       [11,  12,    13,   14,   15,  16,    21,  22,  23],
   classes_mapped_benthic:      [11,    12,   13,  14,    15,   18],
   classes_mapped_names_geo: ['SL','DL', 'IRF','ORF','RC', 'TRF','SS','SE', 'PL'],
   classes_mapped_names_benthic: ['SA', 'RU', 'RO', 'SG', 'CO', 'BMA' ],
};


var classes_mapped=(vars.geomorphic) ? classesList.classes_mapped_geo : classesList.classes_mapped_benthic;
var classes_names=(vars.geomorphic) ? classesList.classes_mapped_names_geo : classesList.classes_mapped_names_benthic;


var probabilities=ee.ImageCollection(classes_mapped.map(function(num){
  var classOfInt=(training_data.filterMetadata('class_num','equals',ee.Number(num))).map(function (feat) {return feat.set('od',1,'classId',classes_names)})//.aside(print,'classOfInt');
  var classN=ee.String(classOfInt.first().get('class_num'));
  print('class_num' , classN,'number of samples for the particular class',classOfInt.size());
  var classesOfNoInt=(training_data.filterMetadata('class_num','not_equals',ee.Number(num))).map(function (feat) {return feat.set('od',0)})//.aside(print,'classOfNoInt');
  var training=pixsegs.sampleRegions(classOfInt.merge(classesOfNoInt),['od'],10);
  var trained=ee.Classifier.smileRandomForest(10).train(training,'od').setOutputMode('PROBABILITY');
  var classified=pixsegs.classify(trained).multiply(100).toInt8();
  var classs=classified//.expression('1-img',{'img':classified});
  return ee.Image(classs);
}));
var probabilities=(probabilities.toBands()).rename(classes_names);
print('probabilities',probabilities);
Map.addLayer(probabilities,{},'probabilities')

Export.image.toAsset({image:probabilities,
                      description:'prob_geo',
                      assetId:'projects/coral_atlas/east_africa/in_out/east_africa_prob_benthic',
                      region:export_geom,
                      scale:vars.export_scale,
                      maxPixels:1e13
                      });


// 5. Export data

var output_name = (vars.geomorphic) ? vars.geomorph_output_name : vars.benthic_output_name
var display_pal = (vars.geomorphic) ? map_palettes.geo : map_palettes.benthic

/*var export_classification = function () {
  //var export_convhull = pixels.select(vars.blue_band).gt(0).reduceToVectors({scale: 1000, maxPixels: 1e13, bestEffort: true, geometry: pixels.select(vars.blue_band).geometry().bounds(100), crs: "EPSG:4326"}).geometry().convexHull({maxError: 100})
  Map.addLayer(export_geom, {}, "Export footprint", true)
  Export.image.toAsset({
    image: raw_classification.set(vars),
    description: output_name,
    assetId: vars.asset_output + output_name,
    region: export_geom,
    scale: vars.export_scale,
    crs: vars.local_epsg,
    maxPixels: 1e13,
    pyramidingPolicy: {'.default': 'mode'}
  })
}*/

if (vars.do_export) {
  //export_classification() // export if wanted
  
  //var export_geom = ee.Geometry.Rectangle(-168.034,-24.0093,162.7417,-7.3087)
  var export_geom = pixsegs.select(1).gt(0).reduceToVectors({scale: 1000, maxPixels: 1e13, bestEffort: true, geometry: region_extent, crs: "EPSG:4326"}).geometry().convexHull({maxError: 100})
  
  Map.addLayer(export_geom, {}, "export footprint", true)
  
  Export.image.toAsset({
    image: raw_classification.set(vars),
    description: output_name,
    assetId: vars.asset_output + 'in_out/' + output_name,
    scale: vars.export_scale,
    region: export_geom,
    maxPixels: 1e13,
    pyramidingPolicy:{'.default': 'mode'},
  })
  
  
  /*
  
  // add raster flag for either side of dateline
  var latlong = ee.Image.pixelLonLat().select('longitude').clip(export_geom)
  var export_stack_east = raw_classification.set(vars).updateMask(latlong.lte(0))
  var export_stack_west = raw_classification.set(vars).updateMask(latlong.gt(0))
  
  var export_geom_east = ee.Geometry.Rectangle(-179.99998,-24.0093,-168.034,-8.081)
  var export_geom_west = ee.Geometry.Rectangle(162.7417,-23.0584,179.99998,-7.3087)
  
  Map.addLayer(export_geom_east, {}, "export footprint east", true)
  Map.addLayer(export_geom_west, {}, "export footprint west", true)
  
  Export.image.toAsset({
    image: export_stack_east,
    description: output_name + '_east',
    assetId: vars.asset_output + 'in_out/' + output_name + '_east',
    scale: vars.export_scale,
    region: export_geom_east,
    maxPixels: 1e13,
    pyramidingPolicy:{'.default': 'mode'},
  })
  
  Export.image.toAsset({
    image: export_stack_west,
    description: output_name + '_west',
    assetId: vars.asset_output + 'in_out/' + output_name + '_west',
    scale: vars.export_scale,
    region: export_geom_west,
    maxPixels: 1e13,
    pyramidingPolicy:{'.default': 'mode'},
  })
  
  */
  
} else {
  if (vars.show_eg_area) {
    Map.addLayer(raw_classification.clip(eg_area), display_pal, output_name + '_raw', false)
  } else {
    Map.addLayer(raw_classification, display_pal, output_name + '_raw', false)
  }
}

// last so it sits on top
Map.addLayer(training_data, {}, "Training point distribution", false) // Training data points
if (vars.use_benthic_points) Map.addLayer(benthic_pts, {}, "Training field point distribution", false) // Training data points