///////////////////////////////
// Global coral atlas project - SWP region
// Contact: mitchell.lyons@gmail.com
// Description:
// - Developing a process to combine OBIA and supervised classification
// - This script loads the pixel-based and segmentation data and training data and exports the training sampled
// - Corresponding '_datagen' script performs the data gathering/segmentation
// - Corresponding '_classification' script performs the classification 
///////////////////////////////

// Table of contents
// 1. Setting constants
// 2. Data loads & vis
// 4. Create training data
// 5. Export data

// Load and libraries needed
var map_palettes = require('users/mitchest/global_reefs:Modules/colour_pals')
var param_module = require('users/mitchest/global_reefs:Modules/reef_params')

// ###########################################
// SENSOR GENERICS
var sensor_params = param_module.dove         //<------------ THIS IS WHERE YOU CHOOSE THE SENSOR
// REGION AND SENSOR SPECIFIC LOAD PATHS
var region_params = param_module.swpac  //<------------ THIS IS WHERE YOU CHOOSE THE REGION
//  ^^ all the data paths are in this module ^^
// ###########################################

// 1. Setting constants

// These will get written to the asset metadata 

var vars = {
  
  // analysis type
  geomorphic: false, // map geomorphic zonation (when set to true) or benthic habitat (when set to false)
  use_benthic_points: false, // true = use benthic field points instead of map
  
  // analysis parameters
  image_data_scale: sensor_params.pixel, // pixel size of the image data
  class_field: 'class_num', // the field in the training data that stores the class integer
  
  // class information for classification, sampling and reporting
  local_epsg: region_params.epsg,
  // trim input data
  trim_training_data: false, // if true, will trim the training data set by the % below
  trim_training_perc: 0.60,
  // geomorphic
  nosamp_class_geo:  [0, 1, 2,    25, 26], // classes not to use/use more
  nosamp_numpix_geo: [0, 0, 10000, 0,  0 ], // set number of pixels to sample from above classes
  // TODO: consider dynamically generating these
  //classes_mapped_geo:       [ 2,  11,  12,  13,   14,   15,  16,  21,  22,  23,  24  ], // classes to map
  //classes_mapped_names_geo: ['D','SL','DL','IRF','ORF','RR','TRF','SS','SE','PL','OCL'],
  // benthic
  nosamp_class_benthic:  [0, 1], // classes not to use/use more
  nosamp_numpix_benthic: [0, 0], // set number of pixels to sample from above classes
  // TODO: consider dynamically generating these
  //classes_mapped_benthic:       [ 3,    4,    11,   12,   13,   14,   15,   16,  17], // classes to map
  //classes_mapped_names_benthic: ['MAN','MU', 'SA', 'RU', 'RO', 'SG', 'CA', 'CO', 'AL'],
  
  
  // export options
  do_export: true, // export the results?
  export_scale: sensor_params.pixel, // pixel size to export at
  geomorph_output_name: region_params.sname + '_' + 'geo_training',
  benthic_output_name: region_params.sname + '_' + 'benthic_training',
  asset_output: region_params.asset, // asset path

}


// 2. Data loads & vis

// load input data
var pixels = ee.ImageCollection(region_params.pixels).mosaic().regexpRename('(^.*$)','$1_p')
var segments = ee.ImageCollection(region_params.segments).mosaic().regexpRename('(^.*$)','$1_s')
var geomorph = ee.FeatureCollection(region_params.geo_train)
var benthic = ee.FeatureCollection(region_params.benthic_train)
if (vars.use_benthic_points) var benthic_pts = ee.FeatureCollection(region_params.benthic_pts)

// Add the raw data
var all_training_data = (vars.geomorphic) ? geomorph : benthic // Set the training points to either geomorphic or benthic
// trim the data (randomly) if needed
if (vars.trim_training_data) {
  all_training_data = all_training_data.randomColumn("random")
  all_training_data = all_training_data.filter(ee.Filter.lte("random", vars.trim_training_perc))
}

// set the class information
var nosamp_class = (vars.geomorphic) ? vars.nosamp_class_geo : vars.nosamp_class_benthic
var nosamp_numpix = (vars.geomorphic) ? vars.nosamp_numpix_geo : vars.nosamp_numpix_benthic
/*var classes_mapped = (vars.geomorphic) ? vars.classes_mapped_geo : vars.classes_mapped_benthic
var classes_mapped_names = (vars.geomorphic) ? vars.classes_mapped_names_geo : vars.classes_mapped_names_benthic*/


/*
make the combined pixels and segemnts data
and ensure they're masked the same
- not sure why, but this masking cross-reference fucks things??
- leaving out for time being
//segments = segments.updateMask(pixels)
//pixels = pixels.updateMask(segments)
*/
var pixsegs = pixels.addBands(segments)
                // test remoing depth from classification
                //.select('b1','b2','b3','b4','waves','red_asm','red_stdDev','ndwi','b1_1','b2_1','b3_1','b4_1','waves_1','red_asm_1','red_stdDev_1','ndwi_1')

Map.centerObject(pixels, 11)

Map.addLayer(pixels, {}, 'per-pixel image data', false)
Map.addLayer(segments, {}, 'segmented image data', false)
Map.addLayer(pixsegs, {}, 'segments + pixels', false)


// 4. Create training data

Map.addLayer(all_training_data, {}, "Training polygons", false)

if (!vars.geomorphic && vars.use_benthic_points) {
  // draw trainign points from cal/val map + input point data set
  var map_pts = ee.Image().byte().paint(all_training_data, vars.class_field).rename(vars.class_field)
                      .updateMask(segments.select('b1').gte(0))
                      .addBands(ee.Image.pixelLonLat())
                      .stratifiedSample({
                        numPoints: vars.train_size,
                        region: all_training_data, // region to sample points from
                        projection: vars.local_epsg,
                        scale: sensor_params.pixel,
                        classValues: nosamp_class,
                        classPoints: nosamp_numpix
                      }).map(function(f) {
                        return f.setGeometry(ee.Geometry.Point([f.get('longitude'), f.get('latitude')]))
                      })
  var train_pts = benthic_pts.merge(map_pts) // use benthic field data poitns to train a map
  
} else {
  // draw trainign points from cal/val map
  var train_pts = ee.Image().byte().paint(all_training_data, vars.class_field).rename(vars.class_field)
                      .updateMask(segments.select('b1').gte(0))
                      .addBands(ee.Image.pixelLonLat())
                      .stratifiedSample({
                        numPoints: vars.train_size,
                        region: all_training_data, // region to sample points from
                        projection: vars.local_epsg,
                        scale: sensor_params.pixel,
                        classValues: nosamp_class,
                        classPoints: nosamp_numpix
                      }).map(function(f) {
                        return f.setGeometry(ee.Geometry.Point([f.get('longitude'), f.get('latitude')]))
                      })
}
// ## If you have training points from multiple UTM zones (and the local epsg is a UTM crs),
// ## then you need to run the above block within each zone and then merge.
// ## See 'gbr_classification' script for an example
//var train_pts = train_pts_cc.merge(train_pts_cbg) // merge to final set

/*
// function to create a X m buffer around the input training data (this may change when segments are used)
var buff_points = function (feature) {
  return feature.buffer(vars.train_point_buff_dist) // should get the 3x3 Landsat neighbourhood
}
var train_pts = train_pts.map(buff_points)
*/

// extract image data for classifier training
if (vars.pixels_or_objects == 'pixels') {
  var training_data = pixels.sampleRegions({
    collection: train_pts,
    properties: [vars.class_field],
    scale: vars.image_data_scale
  })
} else if (vars.pixels_or_objects == 'objects') {
  var training_data = segments.sampleRegions({
    collection: train_pts,
    properties: [vars.class_field],
    scale: vars.image_data_scale
  })
} else {
  var training_data = pixsegs.sampleRegions({
    collection: train_pts,
    properties: [vars.class_field],
    scale: vars.image_data_scale,
    geometries: false
  })
}
//print(benthic_pts.size())
//print(ignore_pts.size())
//print(train_pts.size())
//print(training_data.size())



// 7. Export data

var output_name = (vars.geomorphic) ? vars.geomorph_output_name : vars.benthic_output_name
var display_pal = (vars.geomorphic) ? map_palettes.geo : map_palettes.benthic

/*var export_classification = function () {
  //var export_convhull = pixels.select(vars.blue_band).gt(0).reduceToVectors({scale: 1000, maxPixels: 1e13, bestEffort: true, geometry: pixels.select(vars.blue_band).geometry().bounds(100), crs: "EPSG:4326"}).geometry().convexHull({maxError: 100})
  Map.addLayer(export_geom, {}, "Export footprint", true)
  Export.image.toAsset({
    image: map_clean.set(vars),
    description: output_name,
    assetId: vars.asset_output + output_name,
    region: export_geom,
    scale: vars.export_scale,
    crs: vars.local_epsg,
    maxPixels: 1e13,
    pyramidingPolicy: {'.default': 'mode'}
  })
}*/

if (vars.do_export) {
  //export_classification() // export if wanted
  
  var export_geom = ee.Geometry.Rectangle(-168.034,-24.0093,162.7417,-7.3087)
  
  // add raster flag for either side of dateline
  var latlong = ee.Image.pixelLonLat().select('longitude').clip(export_geom)
  var export_stack_east = map_clean.set(vars).updateMask(latlong.lte(0))
  var export_stack_west = map_clean.set(vars).updateMask(latlong.gt(0))
  
  var export_geom_east = ee.Geometry.Rectangle(-179.99998,-24.0093,-168.034,-8.081)
  var export_geom_west = ee.Geometry.Rectangle(162.7417,-23.0584,179.99998,-7.3087)
  
  Map.addLayer(export_geom_east, {}, "export footprint east", true)
  Map.addLayer(export_geom_west, {}, "export footprint west", true)
  
  Export.image.toAsset({
    image: export_stack_east,
    description: output_name + '_east',
    assetId: vars.asset_output + 'in_out/' + output_name + '_east',
    scale: vars.export_scale,
    region: export_geom_east,
    maxPixels: 1e13,
    pyramidingPolicy:{'.default': 'mode'},
  })
  
  Export.image.toAsset({
    image: export_stack_west,
    description: output_name + '_west',
    assetId: vars.asset_output + 'in_out/' + output_name + '_west',
    scale: vars.export_scale,
    region: export_geom_west,
    maxPixels: 1e13,
    pyramidingPolicy:{'.default': 'mode'},
  })
  
} else {
  if (vars.show_eg_area) {
    Map.addLayer(map_clean.clip(eg_area), display_pal, output_name + '_final', false)
  } else {
    Map.addLayer(map_clean, display_pal, output_name + '_final', false)
  }
}

// last so it sits on top
Map.addLayer(train_pts, {}, "Training point distribution", false) // Training data points
if (vars.use_benthic_points) Map.addLayer(benthic_pts, {}, "Training field point distribution", false) // Training data points
Map.addLayer(training_data, {}, "Image training point distribution", false) // Training data points