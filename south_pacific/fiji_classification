/**** Start of imports. If edited, may not auto-convert in the playground. ****/
var map_centre = /* color: #d63000 */ee.Geometry.Point([178.25660705566406, -18.242394531116258]),
    s2_vis = {"opacity":1,"bands":["b4","b3","b2"],"min":309.90909090909093,"max":2502.5,"gamma":1},
    eg_area = 
    /* color: #d63000 */
    /* displayProperties: [
      {
        "type": "rectangle"
      },
      {
        "type": "rectangle"
      }
    ] */
    ee.Geometry.MultiPolygon(
        [[[[178.1914966082618, -19.126850353489502],
           [178.1914966082618, -19.126850353489502],
           [178.1914966082618, -19.126850353489502],
           [178.1914966082618, -19.126850353489502]]],
         [[[178.1896083331153, -19.126039427046837],
           [178.1896083331153, -19.156203209515112],
           [178.24265169859382, -19.156203209515112],
           [178.24265169859382, -19.126039427046837]]]], null, false);
/***** End of imports. If edited, may not auto-convert in the playground. *****/
///////////////////////////////
// Global coral atlas project - Fiji region
// Contact: mitchell.lyons@gmail.com
// Description:
// - Developing a process to combine OBIA and supervised classification
// - This script loads the pixel-based and segmentation data and applies a mchaine learning classifier
// - Corresponding '_datagen' script performs the data gathering/segmentation
///////////////////////////////

// Table of contents
// 1. Setting constants
// 2. Data loads & vis
// 3. Divide into potential mapping zones (not utilised yet really)
// 4. Create training data
// 5. Train and fit models
// 6. Clean up minimum mapping unit
// 7. Export data

// Load and libraries needed
var map_palettes = require('users/mitchest/global_reefs:Modules/colour_pals')
var param_module = require('users/mitchest/global_reefs:Modules/reef_params')
var slider_module = require('users/mitchest/global_reefs:Modules/threshold_sliders')

// ###########################################
// SENSOR GENERICS
var sensor_params = param_module.dove         //<------------ THIS IS WHERE YOU CHOOSE THE SENSOR
// REGION AND SENSOR SPECIFIC LOAD PATHS
var region_params = param_module.fiji_htv2  //<------------ THIS IS WHERE YOU CHOOSE THE REGION
//  ^^ all the data paths are in this module ^^
// ###########################################

// 1. Setting constants

// These will get written to the asset metadata 

var vars = {
  
  // analysis type
  geomorphic: true, // map geomorphic zonation (when set to true) or benthic habitat (when set to false)
  use_benthic_points: false, // true = use benthic field points instead of map
  thresholding: false, // should all the thresholdable layers be added to the map?
  threshold_pixels: true, // whether the thresholding should be on the pixel or segment data
  // choose whether pixels, segments or both should be used to train the classifier:
  pixels_or_objects: 'both', // one of 'both', 'pixels' or 'segments', where 'both' means both pixel and object input data combined 
  
  // analysis parameters
  image_data_scale: sensor_params.pixel, // pixel size of the image data
  blue_nir_bands: (sensor_params.sname == 'dove') ? ['b1','b4'] : ['B2','B5'], // only handles Landsat/Sentinel-2/Dove
  blue_band: (sensor_params.sname == 'dove') ? 'b1' : 'B2', // only handles Landsat/Sentinel-2/Dove
  class_field: 'class_num', // the field in the training data that stores the class integer
  small_object_filter: 50, // size in pixels (output scale) for small object removal
  
  // add relative band brightness to predictor variables?
  use_brightness: true,
  
  // zone thresholds
  //reef_top_depth: 4.5, // areas above this depth will be split into 'reef top'
  
  // classification params
  train_size: 2000,
  rf_trees: 40, // number of random forest trees (per class)
  rf_minLeafPop: 1, // minimum leaf population for random forest
  rf_varPerSplit: 0, // default sqrt(n(k))
  set_seed: 42, // set a seed so results are repeatable

  // class information for classification, sampling and reporting
  // trim input data
  trim_training_data: false, // if true, will trim the training data set by the % below
  trim_training_perc: 0.6,
  // geomorphic
  nosamp_class_geo:  [0, 1, 2,    25, 26], // classes not to use/use more
  nosamp_numpix_geo: [0, 0, 5000, 0,  0 ], // set number of pixels to sample from above classes
  // TODO: consider dynamically generating these
  //classes_mapped_geo:       [ 2,  11,  12,  13,   14,   15,  16,  21,  22,  23,  24  ], // classes to map
  //classes_mapped_names_geo: ['D','SL','DL','IRF','ORF','RR','TRF','SS','SE','PL','OCL'],
  // benthic
  nosamp_class_benthic:  [0,    1,2], // classes not to use/use more
  nosamp_numpix_benthic: [5000, 0,0], // set number of pixels to sample from above classes
  // TODO: consider dynamically generating these
  //classes_mapped_benthic:       [ 3,    4,    11,   12,   13,   14,   15,   16,  17], // classes to map
  //classes_mapped_names_benthic: ['MAN','MU', 'SA', 'RU', 'RO', 'SG', 'CA', 'CO', 'AL'],
  
  // results/layers to show
  show_intermediates: false, // show separate intermediate layers (e.g. reef top, reef crest etc.)
  show_eg_area: false, // contrain the map add to the corresponding example_area polygon geomtery (you can change that)
                              // - you can either set this, or have it false and just navigate to the area you want to see (keeping in mind ALL tiles in the zoom area will calcualte)
  
  // export options
  do_export: false, // export the results?
  export_scale: sensor_params.pixel, // pixel size to export at
  geomorph_output_name: region_params.sname + '_' + sensor_params.sname + '_' + region_params.tide + '_geo',
  benthic_output_name: region_params.sname + '_' + sensor_params.sname + '_' + region_params.tide + '_benthic',
  asset_output: region_params.asset, // asset path

}

// 2. Data loads & vis

// load input data
var pixels = ee.Image(region_params.dove_pixels)
var segments = ee.Image(region_params.dove_segments)
var geomorph = ee.FeatureCollection(region_params.geo_train)
var benthic = ee.FeatureCollection(region_params.benthic_train)
if (vars.use_benthic_points) var benthic_pts = ee.FeatureCollection(region_params.benthic_pts)

// Add the raw data
var all_training_data = (vars.geomorphic) ? geomorph : benthic // Set the training points to either geomorphic or benthic
// trim the data (randomly) if needed
if (vars.trim_training_data) {
  all_training_data = all_training_data.randomColumn("random")
  all_training_data = all_training_data.filter(ee.Filter.lte("random", vars.trim_training_perc))
}

// set the class information
var nosamp_class = (vars.geomorphic) ? vars.nosamp_class_geo : vars.nosamp_class_benthic
var nosamp_numpix = (vars.geomorphic) ? vars.nosamp_numpix_geo : vars.nosamp_numpix_benthic
/*var classes_mapped = (vars.geomorphic) ? vars.classes_mapped_geo : vars.classes_mapped_benthic
var classes_mapped_names = (vars.geomorphic) ? vars.classes_mapped_names_geo : vars.classes_mapped_names_benthic*/


// Add any extra indices needed
if (vars.use_brightness) {
  segments = segments
    .addBands()
    segments.expression(' B / (B + G + R)', {
      'B': reflec.select('b1'),
      'G': reflec.select('b2'),
      'R': reflec.select('b3') }).rename('b_bri')
    .addBands(
    segments.expression(' G / (B + G + R)', {
      'B': reflec.select('b1'),
      'G': reflec.select('b2'),
      'R': reflec.select('b3') }).rename('g_bri'))
    .addBands(
    segments.expression(' R / (B + G + R)', {
      'B': reflec.select('b1'),
      'G': reflec.select('b2'),
      'R': reflec.select('b3') }).rename('r_bri'))
    
    pixels = pixels
    .addBands()
    pixels.expression(' B / (B + G + R)', {
      'B': reflec.select('b1'),
      'G': reflec.select('b2'),
      'R': reflec.select('b3') }).rename('b_bri')
    .addBands(
    pixels.expression(' G / (B + G + R)', {
      'B': reflec.select('b1'),
      'G': reflec.select('b2'),
      'R': reflec.select('b3') }).rename('g_bri'))
    .addBands(
    pixels.expression(' R / (B + G + R)', {
      'B': reflec.select('b1'),
      'G': reflec.select('b2'),
      'R': reflec.select('b3') }).rename('r_bri'))
}


// ndwi (not really, but conceptually achieves it when everything is water...)
segments = segments.addBands(
  segments.normalizedDifference(vars.blue_nir_bands).rename('ndwi'))
pixels = pixels.addBands(
  pixels.normalizedDifference(vars.blue_nir_bands).rename('ndwi'))

// make the combined pixels and segemnts data
// and ensure they're masked the same
segments = segments.updateMask(pixels)
pixels = segments.updateMask(segments)
var pixsegs = pixels.addBands(segments)
                // test remoing depth from classification
                //.select('b1','b2','b3','b4','waves','red_asm','red_stdDev','ndwi','b1_1','b2_1','b3_1','b4_1','waves_1','red_asm_1','red_stdDev_1','ndwi_1')

Map.centerObject(map_centre, 11)

Map.addLayer(pixels, s2_vis, 'per-pixel image data', false)
Map.addLayer(segments, s2_vis, 'segmented image data', false)
Map.addLayer(pixsegs, s2_vis, 'segments + pixels', false)


// ################################################
// Add the threshold slider layers
// ################################################

if (vars.thresholding) {
  
  var thresh_dat = (vars.threshold_pixels) ? pixels : segments
  
  var bw_pal = {'palette': '000000,ffffff','min':-9999, 'max': -9999}
  var red_pal = {'palette': '000000,f03b20','min':-9999, 'max': -9999}
  
  // N.B. these are all generic and come from mitchest/global_reefs/Modules/threshold_sliders
  slider_module.add_depth(thresh_dat)
  slider_module.add_waves(thresh_dat)
  slider_module.add_slope(thresh_dat)
  slider_module.add_b1(thresh_dat)
  slider_module.add_b2(thresh_dat)
  slider_module.add_b3(thresh_dat)
  slider_module.add_b4(thresh_dat)
  if (sensor_params.sname != 'dove') slider_module.add_b5(thresh_dat)
  slider_module.add_depthsd(thresh_dat)
  slider_module.add_redsd(thresh_dat)
  slider_module.add_ndwi(thresh_dat)
  slider_module.add_idm(thresh_dat)
  slider_module.add_depth_depthvar(thresh_dat)
  
}
  
// ################################################
// End of adding threshold slider layers
// ################################################


// 3. Divide into potential mapping zones

/*

var reef_top = pixels.select('depth').gt(vars.reef_top_depth)

if (vars.show_intermediates) {
  Map.addLayer(reef_top, {}, "reef top", false)
}

*/


// 4. Create training data

Map.addLayer(all_training_data, {}, "Training polygons", false)

if (!vars.geomorphic && vars.use_benthic_points) {
  // need to get background pts form the map
  var map_pts = ee.Image().byte().paint(all_training_data, vars.class_field).rename(vars.class_field)
                      .addBands(ee.Image.pixelLonLat())
                      .stratifiedSample({
                        numPoints: vars.train_size,
                        region: all_training_data, // region to sample points from
                        projection: "EPSG:32755",
                        scale: sensor_params.pixel,
                        classValues: nosamp_class,
                        classPoints: nosamp_numpix
                      }).map(function(f) {
                        return f.setGeometry(ee.Geometry.Point([f.get('longitude'), f.get('latitude')]))
                      })
  var train_pts = benthic_pts.merge(map_pts) // use benthic field data poitns to train a map
  
} else {
  // draw trainign points from cal/val map
  var train_pts = ee.Image().byte().paint(all_training_data, vars.class_field).rename(vars.class_field)
                      .addBands(ee.Image.pixelLonLat())
                      .stratifiedSample({
                        numPoints: vars.train_size,
                        region: all_training_data, // region to sample points from
                        projection: "EPSG:32755",
                        scale: sensor_params.pixel,
                        classValues: nosamp_class,
                        classPoints: nosamp_numpix
                      }).map(function(f) {
                        return f.setGeometry(ee.Geometry.Point([f.get('longitude'), f.get('latitude')]))
                      })
}
// ## If you have training points from multiple UTM zones,
// ## then you need to run the above block within each zone and then merge.
// ## See 'gbr_classification' script for an example
//var train_pts = train_pts_cc.merge(train_pts_cbg) // merge to final set

/*
// function to create a X m buffer around the input training data (this may change when segments are used)
var buff_points = function (feature) {
  return feature.buffer(vars.train_point_buff_dist) // should get the 3x3 Landsat neighbourhood
}
var train_pts = train_pts.map(buff_points)
*/

// extract image data for classifier training
if (vars.pixels_or_objects == 'pixels') {
  var training_data = pixels.sampleRegions({
    collection: train_pts,
    properties: [vars.class_field],
    scale: vars.image_data_scale
  })
} else if (vars.pixels_or_objects == 'objects') {
  var training_data = segments.sampleRegions({
    collection: train_pts,
    properties: [vars.class_field],
    scale: vars.image_data_scale
  })
} else {
  var training_data = pixsegs.sampleRegions({
    collection: train_pts,
    properties: [vars.class_field],
    scale: vars.image_data_scale,
    geometries: false
  })
}
//print(benthic_pts.size())
//print(ignore_pts.size())
//print(train_pts.size())
//print(training_data.size())

// 5. Train and fit models

// parameterise and train the classifier (random forest in this case)
var rf_classifier = ee.Classifier.randomForest({
  numberOfTrees: vars.rf_trees,
  minLeafPopulation: vars.rf_minLeafPop,
  variablesPerSplit: vars.rf_varPerSplit,
  seed: vars.set_seed
}).train(training_data, vars.class_field)
// fit the classificaiton model
if (vars.pixels_or_objects == 'pixels') {
  var raw_classification = pixels.classify(rf_classifier).toUint8()
} else if (vars.pixels_or_objects == 'objects') {
  var raw_classification = segments.classify(rf_classifier).toUint8()
} else {
  var raw_classification = pixsegs.classify(rf_classifier).toUint8()
}


// 6. Remove objects below minimum mapping unit

var class_extent_mask = raw_classification.gte(1) // just so it doesn't balloon out

// make a smooth underlay to replace the minimum mapping unit
var map_smooth = raw_classification
                    .focal_mode({
                      radius: ee.Number(vars.small_object_filter).sqrt().int8(),
                      kernelType: 'circle', units: 'pixels', iterations: 1
                    })
                    .updateMask(class_extent_mask)

// replace small objects with the smooth underlay
var map_clean = raw_classification.where({
  test: raw_classification.connectedPixelCount(vars.small_object_filter, false).lt(vars.small_object_filter), 
  value: map_smooth
})


// 7. Export data

var output_name = (vars.geomorphic) ? vars.geomorph_output_name : vars.benthic_output_name
var display_pal = (vars.geomorphic) ? map_palettes.geo : map_palettes.benthic

var export_classification = function () {
  var export_convhull = pixels.select(vars.blue_band).gt(0).reduceToVectors({scale: 1000, maxPixels: 1e13, bestEffort: true, geometry: pixels.select(vars.blue_band).geometry().bounds()}).geometry().convexHull({maxError: 100})
  Map.addLayer(export_convhull, {}, "Export footprint", true)
  Export.image.toAsset({
    image: map_clean.set(vars),
    description: output_name,
    assetId: vars.asset_output + output_name,
    region: export_convhull,
    scale: vars.export_scale,
    maxPixels: 1e13,
    pyramidingPolicy: {'.default': 'mode'}
  })
}

if (vars.do_export) {
  export_classification() // export if wanted
} else {
  if (vars.show_eg_area) {
    Map.addLayer(map_clean.clip(eg_area), display_pal, output_name + '_final', false)
  } else {
    Map.addLayer(map_clean, display_pal, output_name + '_final', false)
  }
}

// last so it sits on top
Map.addLayer(train_pts, {}, "Training point distribution", false) // Training data points
if (vars.use_benthic_points) Map.addLayer(benthic_pts, {}, "Training field point distribution", false) // Training data points
Map.addLayer(training_data, {}, "Image training point distribution", false) // Training data points